{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = spark.read.csv(\"../Data/broadcast_logs/BroadcastLogs_2018_Q3_M8_sample.csv\",\n",
    "                      sep = \"|\",\n",
    "                      header=True,\n",
    "                      inferSchema=True,\n",
    "                      timestampFormat=\"yyyy-MM-dd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = logs.withColumn(\n",
    "            \"Duration_seconds\",\n",
    "            (\n",
    "            F.col(\"Duration\").substr(1,2).cast(\"int\")*60*60 +\n",
    "            F.col(\"Duration\").substr(4,2).cast(\"int\")*60 +\n",
    "            F.col(\"Duration\").substr(7,2).cast(\"int\")\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+\n",
      "|        Duration|dur_sec|\n",
      "+----------------+-------+\n",
      "|01:59:30.0000000|   7170|\n",
      "|00:31:00.0000000|   1860|\n",
      "|00:28:08.0000000|   1688|\n",
      "|00:10:30.0000000|    630|\n",
      "|00:32:00.0000000|   1920|\n",
      "|00:30:00.0000000|   1800|\n",
      "|00:00:35.0000000|     35|\n",
      "|00:01:39.0000000|     99|\n",
      "|00:55:03.0000000|   3303|\n",
      "|00:30:03.0000000|   1803|\n",
      "|00:29:50.0000000|   1790|\n",
      "|00:10:47.0000000|    647|\n",
      "|00:04:00.0000000|    240|\n",
      "|00:03:47.0000000|    227|\n",
      "|00:37:24.0000000|   2244|\n",
      "|00:51:09.0000000|   3069|\n",
      "|00:24:11.0000000|   1451|\n",
      "|00:01:40.0000000|    100|\n",
      "|00:44:58.0000000|   2698|\n",
      "|00:19:06.0000000|   1146|\n",
      "+----------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs.select(F.col(\"Duration\"),\n",
    "            (\n",
    "            F.col(\"Duration\").substr(1,2).cast(\"int\")*60*60 +\n",
    "            F.col(\"Duration\").substr(4,2).cast(\"int\")*60 +\n",
    "            F.col(\"Duration\").substr(7,2).cast(\"int\")).alias(\"dur_sec\")).distinct().show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_identifier = spark.read.csv(\"../Data/broadcast_logs/referenceTables/LogIdentifier.csv\",\n",
    "                      sep = \"|\",\n",
    "                      header=True,\n",
    "                      inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_identifier = logs_identifier.where(F.col(\"PrimaryFG\") == 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
